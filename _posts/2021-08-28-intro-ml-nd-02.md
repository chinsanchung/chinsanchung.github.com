---
title: 'Introduction to Machine Learning with TensorFlow - Image Classifier'
layout: single
author_profile: false
read_time: false
comments: false
share: true
related: true
categories:
  - project
toc: true
toc_sticky: true
toc_labe: 목차
description: Introduction to Machine Learning with TensorFlow 의 두 번째 프로젝트 "Image Classifier"를 설명합니다.
tags:
  - nanodegree
---

유다시티의 **Introduction to Machine Learning with TensorFlow** 의 두 번째 번째 프로젝트 "Image Classifier"를 진행하면서, 주어진 문제의 정답을 왜 이렇게 작성했는지를 정리하고자 합니다. 이번 프로젝트는 크게 "이미지를 분류하는 신경망 모델 만들기"와 "작성한 신경망을 커맨드 라인 애플리케이션으로 변환하기" 두 가지로 구분됩니다.

# 1. 이미지 분류기

## 개요: 프로젝트에 대한 설명

텐서플로우를 이용해 이미지를 분류하는 스마트폰 앱을 만드는 것이 목적입니다. 이번 프로젝트에서는 다른 종들의 꽃을 인식하는 학습을 진행합니다. [옥스포드가 제공한 102 품종이 있는 데이터](https://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html)를 활용합니다.

## 필요한 자원 불러오기

Udacity 에서 GPU 를 사용할 수 있는 주피터 노트북을 제공하여 그 노트북을 바탕으로 진행했습니다. 그런데 제 경우 처음에 제시한 가이드라인대로 실행하던 중,

```python
dataset, dataset_info = tfds.load('oxford_flowers102', as_supervised=True, with_info=True)
```

이 코드에서 Extraction completed 이 작동을 멈추며 아래의 에러를 출력했습니다..

```
NonMatchingChecksumError: Artifact https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz, downloaded to /root/tensorflow_datasets/downloads/robots.ox.ac.uk_vgg_flowers_102_102flowersoWedSp98maBn1wypsDib6T-q2NVbO40fwvTflmPmQpY.tgz.tmp.d6b82e2502ea41358ff0550d404b17fd/102flowers.tgz, has wrong checksum.
```

[Udacity Knowledge](https://knowledge.udacity.com/questions/528691)을 참고해 노트북의 실행 순서를 게시글의 답변대로 실행해서 문제를 해결했습니다.

```
#The new version of dataset is only available in the tfds-nightly package.
%pip --no-cache-dir install tfds-nightly --user
!pip install tensorflow --upgrade --user
# 이후 커널을 재시작합니다.
```

```python
# 라이브러리를 가져옵니다.
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_hub as hub
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```

```
# Download data to default local directory "~/tensorflow_datasets"
!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums=True --datasets=oxford_flowers102
```

tensorflow_datasets 의 oxford_flowers102 데이터셋은 훈련, 검증, 테스트 셋을 이미 구분을 한 데이터셋이므로 임의로 나눌 필요가 없습니다.

```python
dataset, dataset_info = tfds.load('oxford_flowers102',
                                  as_supervised=True, with_info=True)

training_set, validation_set, test_set = dataset['train'], dataset['validation'], dataset['test']
```

## 데이터셋 탐색하기

tensorflow_datasets 에서 제공하는 DatasetInfo 에서 각 데이터셋의 예제와 클래스의 개수를 가져와 데이터의 구성을 확인합니다.

```python
print('num of examples: training_set: {}, validation_set: {}, test_set: {}'.format(
    dataset_info.splits['train'].num_examples,
    dataset_info.splits['validation'].num_examples,
    dataset_info.splits['test'].num_examples
    ))

print('num of classes: {}'.format(dataset_info.features['label'].num_classes))
```

훈련 세트에서 3개의 이미지와 라벨을 출력합니다.

```python
class_names = dataset_info.features['label'].names

images = []
labels = []
for image, label in training_set.take(3):
    images.append(image.numpy())
    labels.append(label.numpy())
print('shape of 3 images:\n', images[0].shape,', ', images[1].shape, ',',  images[2].shape)
print('shape of 3 labels:\n', class_names[0],', ', class_names[1],', ', class_names[2])
```

이번에는 하나의 이미지를 출력합니다. 이미지의 제목을 해당 이미지의 라벨로 설정합니다.

```python
plt.title(class_names[0])
plt.imshow(images[0])
plt.show()
```

### 라벨 매핑

데이터셋의 'label' 특성에서 가져오는 대신 Udacity 에서 제공한 "label_map.json"에서 불러와봅니다.

```python
import json
with open('label_map.json', 'r') as f:
  class_names = json.laod(f)
```

## 파이프라인 제작하기

```python
# 훈련 세트의 총 개수
total_train_num = dataset_info.splits['train'].num_examples
# 이미지를 224x224 사이즈로 정규화할 때 사용합니다.
image_size = 224
# 배치 크기를 지정합니다.
batch_size = 64

def nomalize_image(image, label):
  # 이미지의 dtype 를 unit8 에서 float32 로 변경합니다.
  image = tf.cast(image, tf.flaot32)
  # 이미지를 224x224 사이즈로 졍규화합니다.
  image = tf.image.resize(image, (image_size, image_size))
  # 이미지를 0 ~ 1 사이의 값으로 변환해 졍규화합니다.
  image /= 255
  return image, label

# 무작위로 데이터를 섞고(shuffle), 정규화하며(map), 배치 크기가 64인 파이프라인을 만듭니다.
training_batches = training_set.shuffle(total_train_num // 4).map(nomalize_image).batch(batch_size).prefetch(1)
validation_batches = validation_set.map(nomalize_image).batch(batch_size).prefetch(1)
testing_batches = test_set.map(nomalize_image).batch(batch_size).prefetch(1)

```

## 모델 구축 및 훈련하기

MobileNet 으로부터 미리 훈련된 모델을 사용하는 **전이 학습**을 합니다. 전이 학습은 특정 환경에서 만들어진 AI 알고리즘을 다른 비슷한 분야에 적용하는 것입니다.[출처](https://blog.lgcns.com/1563) 주요 사용 목적은 충분한 데이터를 학습함 모델을 데이터가 부족한 분야에 적용하는 것입니다.

```python
# 전이 학습에 사용할 모델을 불러옵니다.
URL = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"
feature_extractor = hub.KerasLayer(URL, input_shape=(image_size, image_size, 3),
                                  trainable=False)
```

여기서 주의할 점은 미리 훈련된 모델 `feature_extractor`의 가중치와 편향을 고정시키는 것입니다. trainable 매개변수를 False 로 하여 고정시켰습니다.

모델을 생성합니다. 마지막 출력층의 개수를 102로 한 이유는 분류해야 할 꽃의 품종의 개수가 102이기 때문입니다.

```python
model = tf.keras.Sequential([
    feature_extractor,
    tf.keras.layers.Dense(102, activation='softmax')
])
# 모델을 컴파일하고 훈련합니다.

```

최적화를 'adam'으로 하는 이유는 효율적인 계산 능력, 적은 메모리 소요, 그리고 데이터와 파라미터가 큰 문제에 적합하기 때문입니다.

```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])

# 훈련하면서 정확도와 손실을 저장합니다.
history = model.fit(training_batches, epochs=20, validation_data=validation_batches,
                  verbose=0, callbacks=[early_stopping])
```

epoch 에 따른 모델의 정확도와 손실을 꺾은선그래프로 그렸습니다.

## 모델 테스트하기

테스트 세트에서의 모델의 성능(정확도, 손실)을 확인합니다.

```python
model.evaluate(testing_batches)
```

## 모델 저장 및 불러오기

모델을 불러올 때, 외부의 모델을 가져왔기 때문에 `custom_objects` 매개변수 없이 모델을 불러오면 에러가 발생합니다. 외부의 모델을 `load_model`에 반영해야 합니다. [출처](https://stackoverflow.com/questions/61814614/unknown-layer-keraslayer-when-i-try-to-load-model)

```python
# 모델을 "saved_model.h5"란 이름으로 저장하기
model.save('saved_model.h5')
```

```python
reloaded_model = tf.keras.models.load_model('saved_model.h5', custom_objects={
    'KerasLayer': hub.KerasLayer
})
reloaded_model
```

## 예측 함수 만들기

`predict`라는 함수를 만드는 문제입니다. 매개변수로 image_path, model, top_k 가 있으며, 확률과 라벨의 인덱스를 출력해야 합니다.

### process_image

이미지 경로를 입력해서 이미지와 해당하는 이미지의 클래스를 구하는 predict_image 함수를 만듭니다. 이후 predict 함수로 구한 결과와 비교하기 위해 사용합니다.

```python
def process_image(image):
  '''
    image: np.asarray 로 변환한 넘파이 배열입니다.
  '''
  image_tensor = tf.convert_to_tensor(image)
  # 224x224 크기로 변환합니다.
  iamge = tf.image.resize(image_tensor, (image_size, image_size))
  # 픽셀을 0 ~ 1 사이의 값으로 정규화합니다.
  image /= 255
  return image
```

### predict

```python
def predict(image_path, model, top_k):
    image_obj = Image.open(image_path)
    image = np.asarray(image_obj)
    # 모델의 훈련을 위해서 (224, 224, 3) 을 (1, 224, 224, 3) 형태로 바꿉니다.
    expanded_img = np.expand_dims(process_image(image), axis=0)
    predictions = model.predict(expanded_img)
    # 예측 결과에서 큰 순서대로 k 개만큼의 값과 인덱스를 찾습니다.
    values, indices = tf.nn.top_k(predictions, k=top_k)
    # class_names 의 키가 0 ~ 101이 아닌 1 ~ 102로 되어 있기 때문입니다.
    indices = 1 + indices[0]
    # [0]을 하는 이유: [[1,2,3]] 이 아닌 [1,2,3] 을 원하기 떄문입니다.
    return values.numpy()[0], indices.numpy().astype(str)
```

# 2. 커맨드 라인 애플리케이션

## 개요: 프로젝트에 대한 설명

꽃을 분류하는 신경망을 파이썬 스크립트 형식으로 실행하는 애플리케이션으로 변환합니다. 기본적으로 입력하는 예시입니다.

```
$ python predict.py ./test_images/cautleya_spicata.jpg my_model.h5
$ python predict.py ./test_images/cautleya_spicata.jpg my_model.h5 --top_k 3
$ python predict.py ./test_images/cautleya_spicata.jpg my_model.h5 --category_names label_map.json
```

### 스크립트에서의 옵션

- 분류에 사용할 이미지를 입력합니다. (필수)
- 이전 과제에서 저장한 신경망 모델의 이름을 입력합니다. (필수)
- `--top_k`: 가장 연관성이 높은 K 개의 클래스를 반환합니다. (선택)

```
$ python predict.py ./test_images/orchid.jpg my_model.h5 --top_k 3
```

- `--category_names`: 꽃의 이름 라벨과 매핑하는 JSON 파일의 경로입니다. (선택)

```
$ python predict.py ./test_images/orchid.jpg my_model.h5 --category_names label_map.json
```

## 스크립트 파싱하기

### argparse

함수를 제작하기에 앞서 argparse 에 대해 이해해야 합니다. [파이썬 공식 문서](https://docs.python.org/ko/3/library/argparse.html)에 따르면 커맨드 인터페이스를 쉽게 작성할 수 있도록 돕는 모듈입니다.

기본적인 사용법은 ArgumentParser 으로 파서를 만들고 후, 그 파서에 `add_argument()`로 인자를 추가합니다. 그리고 `parse_args()`로 인자를 파싱합니다.

이번 프로젝트의 `python test.py first_value second_value` 을 콘솔에 입력한다고 가정하겠습니다.

```python
parser = argparse.ArgumentParser(description='You can write description')
parser.add_argument('first')
parser.add_argument('second')
args = parser.parse_args()
print(args.first) # >> first_value
print(args.second) # >> second_value
```

### 스크립트로 파일을 실행하는지 파악하기

`python test.py`를 콘솔에 입력했을 때 그것을 인식하고, 어떠한 명령을 실행할 때 사용했습니다.

`__name`은 모듈의 이름을 저장하는 변수인데, 파이썬 인터프리터로 파일을 직접 실행할 때는 모듈의 이름 대신 `__main__`을 이름으로 사용합니다. 따라서 아래의 조건문은 인터프리터로 실행을 하는지 여부를 확인해서, 만약 그렇다면 다음의 코드를 실행하라는 의미인 것입니다.

이것을 통해 argparse 로 콘솔에 입력한 내용을 파싱한 후 분류기를 작동시킬 것입니다.

```python
if __name__ == '__main__':
  print('TEST')
```

간단한 예시를 작성했습니다. [자습서](https://docs.python.org/ko/3/howto/argparse.html#id1)를 통해 더 자세한 내용을 파악하실 수 있습니다.

## 이미지를 분류하는 클래스 작성하기

클래스 `Classifier`는 크게 모델을 불러오는 `__load_model`, JSON 파일에서 클래스의 이름들을 불러오는 `__load_class_names`, 이미지를 정규화하는 `__process_image`, 이미지의 형식을 변환하는 `__convert_image`, 마지막으로 예측을 수행하는 `predict` 메소드로 구성됩니다.

- 참고로 메소드 앞에 `__`으로 입력한 것은 객체 지향 문법 중 하나로, 해당 클래스에서만 접근할 수 있도록 하는 "private" 설정입니다.

생성자를 선언할 때, 입력의 선택사항인 `top_k`, `json_name`을 삼항연산자를 이용해 기본값을 지정했습니다.

다음은 함수의 전문입니다.

```python
import argparse
import json
import numpy as np
import tensorflow as tf
import tensorflow_hub as hub
from PIL import Image

# python predict.py ./test_images/cautleya_spicata.jpg my_model.h5
# python predict.py ./test_images/cautleya_spicata.jpg my_model.h5 --top_k 3
# python predict.py ./test_images/cautleya_spicata.jpg my_model.h5 --category_names label_map.json
class Classifier:
    def __init__(self, image_path, model_name, top_k, json_name):
        self.image_path = image_path
        self.model_name = model_name
        self.top_k = top_k if top_k != None else 1
        self.json_name = json_name if json_name != None else 'label_map.json'
        self.image_size = 224

    def __load_model(self):
        model = tf.keras.models.load_model(self.model_name, custom_objects={ 'KerasLayer': hub.KerasLayer },
                                          compile=False)
        return model
    def __load_class_names(self):
        with open(self.json_name, 'r') as f:
            class_names = json.load(f)
        return class_names
    def __process_image(self, image):
        image_tensor = tf.convert_to_tensor(image)
        image = tf.image.resize(image_tensor, (self.image_size, self.image_size))
        image /= 255
        return image
    def __convert_image(self):
        image_obj = Image.open(self.image_path)
        image_array = np.asarray(image_obj)
        expanded_img = np.expand_dims(self.__process_image(image_array), axis=0)
        return expanded_img
    def predict(self):
        expanded_img = self.__convert_image()
        model = self.__load_model()
        print('MODEL:::', model)
        predictions = model.predict(expanded_img)
        values, indices = tf.nn.top_k(predictions, k=self.top_k)
        indices = 1 + indices[0]

        class_names = self.__load_class_names()
        converted_indices = indices.numpy().astype(str)
        classes_with_name = [class_names[x] for x in converted_indices]
        return classes_with_name

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('image_path')
    parser.add_argument('model_name')
    parser.add_argument('--top_k', type=int)
    parser.add_argument('--category_names')

    args = parser.parse_args()
#     print(args)
    classifier = Classifier(args.image_path, args.model_name, args.top_k, args.category_names)
    print(">>> PREDICTED FLOWER NAME: ", classifier.predict())
```

# 프로젝트를 마치며

이미지 분류를 위한 신경망 모델을 처음부터 차근차근 진행할 수 있었습니다. 이미지의 개수가 작기 때문에, 모델의 예측률을 높이기 위해 전이 학습을 진행했는데 책으로 공부한 적이 없던 새로운 방법이었습니다. 다만, 전이 학습으로 모델을 불러옴으로써 모델의 작동 방식이나 형태를 깊게 이해하기 어려웠던 점은 아쉬웠습니다. 모델의 마지막에 `EarlyStopping`으로 과대적합을 막으려 했지만 그리 큰 효과를 거두진 못했습니다.

두 번째 과제에서는 스크립트로 매개변수를 실행하는 법을 찾고, 클래스를 만들어 분류기를 만드는 과정이 즐거웠고, 파이썬 클래스에서도 객체 지향 문법대로 private 를 선언할 수 있다는 것, `if __name__ == "__main__":`으로 스크립트로 파일을 실행하는 것을 인식하는 법, 마지막으로 `argparse` 모듈의 사용법을 배울 수 있었습니다.

다음에 딥러닝을 수행할 때는 처음부터 모델의 은닉층이나 콜백을 직접 효율적으로 만들면서 예측률을 높여보고 싶습니다.
