---
title: 'Introduction to Machine Learning with TensorFlow - Finding Donors for CharityML'
layout: single
author_profile: false
read_time: false
comments: false
share: true
related: true
categories:
  - project
toc: true
toc_sticky: true
toc_labe: 목차
description: Introduction to Machine Learning with TensorFlow 의 첫 프로젝트를 어떻게 작성했는지를 설명합니다.
tags:
  - project
  - nanodegress
---

## 개요

유다시티의 **Introduction to Machine Learning with TensorFlow** 의 첫 번째 프로젝트 "Finding Donors for CharityML"를 진행하면서, 주어진 데이터를 어떻게 분석했는지 그리고 문제의 정답을 왜 이렇게 작성했는지를 정리하고자 합니다.

어떤 문제를 풀었는지 다 설명하기. 미리 요약해서 두괄식으로 적는다는 생각으로. 내 현재 실력을 증빙할 만한 확실한 내용으로 쓰기.

### 프로젝트에 대한 설명

이 프로젝트의 목표는 "수입이 $50,000 보다 큰 사람은 자선단체에 기부를 할 것이다."라는 가정 하에, 45221명의 데이터를 훈련시켜서 수입이 50,000 달러 이상인 사람을 예측하는 것입니다. 데이터 컬럼에 대한 설명을 [깃허브 레퍼지토리](https://github.com/udacity/intro-to-ml-tensorflow/tree/master/projects/p1_charityml)에서 가져왔습니다.

**Features**

- `age`: Age
- `workclass`: Working Class (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked)
- `education_level`: Level of Education (Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool)
- `education-num`: Number of educational years completed
- `marital-status`: Marital status (Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse)
- `occupation`: Work Occupation (Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces)
- `relationship`: Relationship Status (Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried)
- `race`: Race (White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black)
- `sex`: Sex (Female, Male)
- `capital-gain`: Monetary Capital Gains
- `capital-loss`: Monetary Capital Losses
- `hours-per-week`: Average Hours Per Week Worked
- `native-country`: Native Country (United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands)

**Target Variable**

- `income`: Income Class (<=50K, >50K)

타깃(종속변수) 항목인 income 을 살펴보니, 이번 문제는 두 클래스 중 하나를 예측하는 이진 분류, 그리고 정답이 있는 데이터를 훈련시키는 지도 학습 알고리즘으로 작성해야 한다는 것을 알 수 있습니다.

## 데이터 준비하기

기계학습을 수행하기 전에 데이터 전처리를 통해 데이터의 품질을 높여 학습에 좋은 영향을 줄 수 있어야 합니다. 이 데이터 세트에서는 `capital-gain` 과 `capital-loss` 항목의 값들이 중간이 없이 좌우로 흩어져 있음을 유다시티 측에서 제시했습니다. 매우 큰 값과 매우 작은 값이 학습 성능에 부정적인 영향을 주지 않도록 로그 변환을 적용했습니다.

```python
# Log-transform the skewed features
skewed = ['capital-gain', 'capital-loss']
features_log_transformed = pd.DataFrame(data = features_raw)
features_log_transformed[skewed] = features_raw[skewed].apply(lambda x: np.log(x + 1))
```

또한, MinMaxScaler 를 이용해 다른 숫자형 특성들을 스케일링하여 값의 범위를 통일시킵니다.

```python
# Import sklearn.preprocessing.StandardScaler
from sklearn.preprocessing import MinMaxScaler

# Initialize a scaler, then apply it to the features
scaler = MinMaxScaler() # default=(0, 1)
numerical = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']

features_log_minmax_transform = pd.DataFrame(data = features_log_transformed)
features_log_minmax_transform[numerical] = scaler.fit_transform(features_log_transformed[numerical])
```

범주형 데이터를 예측에 활용하기 위해 숫자형 값으로 바꾸는 `one-hot-encoding`으로 범주형 클래스의 개수만큼 특성을 늘렸습니다.

```python
# TODO: One-hot encode the 'features_log_minmax_transform' data using pandas.get_dummies()
features_final = pd.get_dummies(features_log_minmax_transform)

# TODO: Encode the 'income_raw' data to numerical values
income = income_raw.apply(lambda x: 0 if x == '<=50K' else 1)
```

마지막으로 훈련 데이터 세트, 테스트 데이터 세트로 분리합니다.

```python
from sklearn.model_selection import train_test_split

# Split the 'features' and 'income' data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(features_final,
                                                    income,
                                                    test_size = 0.2,
                                                    random_state = 0)
```
